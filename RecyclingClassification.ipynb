{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f39ae73",
   "metadata": {},
   "source": [
    "Classification of recycling waste into different classes.\n",
    "Use the TrashNet (resized) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17345d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0783005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '/home/tensorflow/waste/datasets/trashnet-resized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e792df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_trash_images = {}\n",
    "for folder in os.listdir(dataset):\n",
    "    if folder == 'trash': continue\n",
    "    non_trash_images[folder] = []\n",
    "    for img_name in os.listdir(os.path.join(dataset, folder)):\n",
    "        non_trash_images[folder].append(\n",
    "                    os.path.join(dataset, folder, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5f94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be48d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trash_categories = list(non_trash_images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "713451ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(non_trash_images)), [len(cat) for cat in non_trash_images.values()])\n",
    "_=plt.xticks(range(len(non_trash_images)), trash_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e2708",
   "metadata": {},
   "source": [
    "Split into training (80), validation (5), test (15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ec906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = {}\n",
    "valid_imgs = {}\n",
    "test_imgs = {}\n",
    "PERC_TRAIN = 0.8\n",
    "PERC_VALID = 0.05\n",
    "PERC_TEST = 0.15\n",
    "for cat, imgs in non_trash_images.items():\n",
    "    train_size = int(PERC_TRAIN*len(imgs))\n",
    "    train_imgs[cat] = imgs[:train_size]\n",
    "    valid_size = int(PERC_VALID*len(imgs))\n",
    "    valid_imgs[cat] = imgs[train_size:train_size+valid_size]\n",
    "    test_imgs[cat] = imgs[train_size+valid_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec86171",
   "metadata": {},
   "source": [
    "Create TFRecords from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f50690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfcfacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc9fe959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def write_to_tfrecord(writer, imgs, cat, catidx):\n",
    "    \"\"\"Write images of the given category to the TF record with writer\"\"\"\n",
    "    for img_path in imgs:\n",
    "        # Process the image\n",
    "        with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
    "            img_data = fid.read()\n",
    "        img_data_io = io.BytesIO(img_data)\n",
    "        image = Image.open(img_data_io)\n",
    "        image = image.resize((227,227))\n",
    "        width, height = image.size\n",
    "        # Prepare the rest of the features\n",
    "        filename = img_path.encode('utf8')\n",
    "        image_format = b'jpg'\n",
    "        # Create the TF record entry\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image/height': _int64_feature(height),\n",
    "            'image/width': _int64_feature(width),\n",
    "            'image/filename': _bytes_feature(filename),\n",
    "            'image/encoded': _bytes_feature(img_data),\n",
    "            'image/format': _bytes_feature(image_format),\n",
    "            'image/class/text': _bytes_feature(cat.encode('utf8')),\n",
    "            'image/class/label': _int64_feature(catidx),\n",
    "        }))\n",
    "        writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e8aea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_train = tf.io.TFRecordWriter(os.path.join(dataset, 'train.record'))\n",
    "writer_test = tf.io.TFRecordWriter(os.path.join(dataset, 'test.record'))\n",
    "writer_valid = tf.io.TFRecordWriter(os.path.join(dataset, 'valid.record'))\n",
    "for idx, cat in enumerate(trash_categories):\n",
    "    write_to_tfrecord(writer_train, train_imgs[cat], cat, idx)\n",
    "    write_to_tfrecord(writer_test, test_imgs[cat], cat, idx)\n",
    "    write_to_tfrecord(writer_valid, valid_imgs[cat], cat, idx)\n",
    "writer_train.close()\n",
    "writer_test.close()\n",
    "writer_valid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e055b5a",
   "metadata": {},
   "source": [
    "Classification will be done using AlexNet:\n",
    "* train the model\n",
    "* convert to TF-Lite for execution on Rpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99cd4dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2527 files belonging to 6 classes.\n",
      "Using 2022 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "            dataset,\n",
    "            validation_split=0.2,\n",
    "            subset='training',\n",
    "            seed=123,\n",
    "            image_size=(227,227),\n",
    "            batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59943ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2527 files belonging to 6 classes.\n",
      "Using 505 files for validation.\n"
     ]
    }
   ],
   "source": [
    "validation_ds = keras.utils.image_dataset_from_directory(\n",
    "            dataset,\n",
    "            validation_split=0.2,\n",
    "            subset='validation',\n",
    "            seed=123,\n",
    "            image_size=(227,227),\n",
    "            batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65d21822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0d5dfbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: <lambda>() takes 1 positional argument but 2 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-4208113c650a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   1860\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 1861\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4983\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4984\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4985\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4986\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4987\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4216\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4218\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4219\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4220\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3149\u001b[0m     \"\"\"\n\u001b[1;32m   3150\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3151\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3152\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3153\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3114\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4193\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   4194\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4195\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4196\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4197\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4123\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4124\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4125\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4126\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4127\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: <lambda>() takes 1 positional argument but 2 were given\n"
     ]
    }
   ],
   "source": [
    "train_ds.map(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
