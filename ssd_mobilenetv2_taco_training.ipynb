{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ac6e05",
   "metadata": {},
   "source": [
    "Training a custom object detector on the Taco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3e13013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71deb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util, label_map_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12f28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_taco_to_normal(taco_bbox):\n",
    "  \"\"\"\n",
    "  Convert a bbox from Taco format (xmin, ymin, width, height)\n",
    "  to normal format (xmin, ymin, xmax, ymax)\n",
    "  \"\"\"\n",
    "  return [taco_bbox[0], taco_bbox[1],\n",
    "          taco_bbox[0]+taco_bbox[2], taco_bbox[1]+taco_bbox[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70990bc2",
   "metadata": {},
   "source": [
    "### 1. Creating TF records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c7d7a3",
   "metadata": {},
   "source": [
    "Create a Pandas Dataframe with columns 'filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax' that  contains the annotations for all images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77561a",
   "metadata": {},
   "source": [
    "Load the annotations from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b1d83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ed0318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taco_path = \"/home/tensorflow/waste/datasets/taco_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53020ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tensorflow/waste/datasets/taco_dataset\n"
     ]
    }
   ],
   "source": [
    "cd $taco_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88c2399",
   "metadata": {},
   "outputs": [],
   "source": [
    "taco_ann_raw = json.load(open('annotations.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3f2d7",
   "metadata": {},
   "source": [
    "Create a mapping between category id and category label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9894f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_dict = {}\n",
    "for cat_desc in taco_ann_raw['categories']:\n",
    "    categories_dict[cat_desc['id']+1] = cat_desc['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbc540",
   "metadata": {},
   "source": [
    "We can have multiple annotations for the same image, if it contains multiple boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f6c4679",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_annotations = {}\n",
    "for img_ann in taco_ann_raw['annotations'][:min(1000, len(taco_ann_raw['annotations']))]:\n",
    "    img_id = img_ann['image_id']\n",
    "    img_category = img_ann['category_id']+1\n",
    "    img_bbox = {'box': bbox_taco_to_normal(img_ann['bbox']),\n",
    "                'category': img_category}\n",
    "    if img_id in image_annotations:\n",
    "        image_annotations[img_id]['bboxes'].append(img_bbox)\n",
    "    else:\n",
    "        img_desc = taco_ann_raw['images'][img_id]\n",
    "        img_height = img_desc['height']\n",
    "        img_width = img_desc['width']\n",
    "        img_link = img_desc['flickr_url']\n",
    "        img_name = img_link.split('/')[-1]\n",
    "        # check if this is a train or test image\n",
    "        img_purpose = None\n",
    "        if os.path.exists(os.path.join(taco_path, 'train', img_name)):\n",
    "            img_purpose = 'train'\n",
    "        else:\n",
    "            img_purpose = 'test'\n",
    "        image_annotations[img_id] = {\"filename\":img_name,\n",
    "                                     \"purpose\": img_purpose,\n",
    "                                    \"width\":img_width,\n",
    "                                    \"height\":img_height,\n",
    "                                    \"bboxes\": [img_bbox]\n",
    "                                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9db30357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'y5A3l6LUzhWEkRac2NfxIYAlhFnA8HSzDl8nyqsZ.jpeg',\n",
       " 'purpose': 'test',\n",
       " 'width': 2988,\n",
       " 'height': 5312,\n",
       " 'bboxes': [{'box': [1483.0, 2475.0, 1867.0, 2909.0], 'category': 6},\n",
       "  {'box': [1484.0, 2835.0, 1558.0, 2908.0], 'category': 8}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_annotations[300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1533d",
   "metadata": {},
   "source": [
    "For each image annotation (with multiple boxes) create a TF example.\n",
    "This must contain:\n",
    "* filename\n",
    "* encoded image\n",
    "* image format (JPG/PNG)\n",
    "* bboxes\n",
    "* category labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27de79b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8477f5b483e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriter_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaco_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'taco_dataset_train.record'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwriter_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaco_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'taco_dataset_test.record'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mann\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_annotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Process the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg_purpose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'purpose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "writer_train = tf.io.TFRecordWriter(os.path.join(taco_path, 'taco_dataset_train.record'))\n",
    "writer_test = tf.io.TFRecordWriter(os.path.join(taco_path, 'taco_dataset_test.record'))\n",
    "for ann in image_annotations.values():\n",
    "    # Process the image\n",
    "    img_purpose = ann['purpose']\n",
    "    with tf.io.gfile.GFile(os.path.join(taco_path, img_purpose, 'small', ann['filename']), 'rb') as fid:\n",
    "        img_data = fid.read()\n",
    "    #img_data_io = io.BytesIO(img_data)\n",
    "    #image = Image.open(img_data_io)\n",
    "    #width, height = image.size\n",
    "    width = ann['width']\n",
    "    height = ann['height']\n",
    "    # Prepare the rest of the features\n",
    "    filename = ann['filename'].encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = [] # This will be the class label\n",
    "    classes = [] # This will be the integer value of the class\n",
    "    # Process the bboxes\n",
    "    for bbox in ann['bboxes']:\n",
    "        classes.append(bbox['category'])\n",
    "        classes_text.append(categories_dict[bbox['category']].encode('utf8'))\n",
    "        xmin, ymin, xmax, ymax = bbox['box']\n",
    "        xmins.append(xmin/width)\n",
    "        xmaxs.append(xmax/width)\n",
    "        ymins.append(ymin/height)\n",
    "        ymaxs.append(ymax/height)\n",
    "    # Create the TF record entry\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(img_data),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    if img_purpose == 'train':\n",
    "        writer_train.write(tf_example.SerializeToString())\n",
    "    else:\n",
    "        writer_test.write(tf_example.SerializeToString())\n",
    "writer_train.close()\n",
    "writer_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f27f0",
   "metadata": {},
   "source": [
    "Now we have training and test records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3a347",
   "metadata": {},
   "source": [
    "Create the label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4cfc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(taco_path, 'label_map.pbtxt'), 'w') as lbl_map:\n",
    "    for cat_id, cat_label in categories_dict.items():\n",
    "        lbl_map.write(f\"item {{\\n\\tid: {cat_id}\\n\\tname: '{cat_label}'\\n}}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c35a3",
   "metadata": {},
   "source": [
    "### 2. Training the model\n",
    "\n",
    "We are starting from the pre-trained SSD MobileNetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d1f2051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tensorflow/waste/work\n"
     ]
    }
   ],
   "source": [
    "cd ~/waste/work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da92fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /home/tensorflow/models/research/object_detection/model_main_tf2.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3499cda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0623 09:37:01.953161 140561471125312 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0623 09:37:01.957745 140561471125312 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0623 09:37:01.962418 140561471125312 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0623 09:37:01.962543 140561471125312 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0623 09:37:02.022024 140561471125312 deprecation.py:345] From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['../datasets/taco_dataset/taco_dataset_train.record']\n",
      "I0623 09:37:02.035578 140561471125312 dataset_builder.py:162] Reading unweighted datasets: ['../datasets/taco_dataset/taco_dataset_train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['../datasets/taco_dataset/taco_dataset_train.record']\n",
      "I0623 09:37:02.035718 140561471125312 dataset_builder.py:79] Reading record datasets for input file: ['../datasets/taco_dataset/taco_dataset_train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0623 09:37:02.035764 140561471125312 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0623 09:37:02.035800 140561471125312 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0623 09:37:02.038843 140561471125312 deprecation.py:345] From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0623 09:37:02.063462 140561471125312 deprecation.py:345] From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0623 09:37:07.756206 140561471125312 deprecation.py:345] From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0623 09:37:10.115186 140561471125312 deprecation.py:345] From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0623 09:37:11.414484 140561471125312 deprecation.py:345] From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/home/tensorflow/.local/lib/python3.6/site-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0623 09:37:37.044914 140557259089664 deprecation.py:548] From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 100 per-step time 5.641s\n",
      "I0623 09:47:00.878482 140561471125312 model_lib_v2.py:707] Step 100 per-step time 5.641s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.74652356,\n",
      " 'Loss/localization_loss': 0.6552064,\n",
      " 'Loss/regularization_loss': 0.15328369,\n",
      " 'Loss/total_loss': 1.5550137,\n",
      " 'learning_rate': 0.0319994}\n",
      "I0623 09:47:00.878863 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.74652356,\n",
      " 'Loss/localization_loss': 0.6552064,\n",
      " 'Loss/regularization_loss': 0.15328369,\n",
      " 'Loss/total_loss': 1.5550137,\n",
      " 'learning_rate': 0.0319994}\n",
      "INFO:tensorflow:Step 200 per-step time 5.198s\n",
      "I0623 09:55:40.682086 140561471125312 model_lib_v2.py:707] Step 200 per-step time 5.198s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.58700526,\n",
      " 'Loss/localization_loss': 0.3471491,\n",
      " 'Loss/regularization_loss': 0.15320154,\n",
      " 'Loss/total_loss': 1.0873559,\n",
      " 'learning_rate': 0.0373328}\n",
      "I0623 09:55:40.682387 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.58700526,\n",
      " 'Loss/localization_loss': 0.3471491,\n",
      " 'Loss/regularization_loss': 0.15320154,\n",
      " 'Loss/total_loss': 1.0873559,\n",
      " 'learning_rate': 0.0373328}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 300 per-step time 5.279s\n",
      "I0623 10:04:28.608558 140561471125312 model_lib_v2.py:707] Step 300 per-step time 5.279s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.53930664,\n",
      " 'Loss/localization_loss': 0.24246801,\n",
      " 'Loss/regularization_loss': 0.1531422,\n",
      " 'Loss/total_loss': 0.93491685,\n",
      " 'learning_rate': 0.0426662}\n",
      "I0623 10:04:28.608823 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.53930664,\n",
      " 'Loss/localization_loss': 0.24246801,\n",
      " 'Loss/regularization_loss': 0.1531422,\n",
      " 'Loss/total_loss': 0.93491685,\n",
      " 'learning_rate': 0.0426662}\n",
      "INFO:tensorflow:Step 400 per-step time 5.258s\n",
      "I0623 10:13:14.363360 140561471125312 model_lib_v2.py:707] Step 400 per-step time 5.258s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.51535994,\n",
      " 'Loss/localization_loss': 0.2529274,\n",
      " 'Loss/regularization_loss': 0.1531298,\n",
      " 'Loss/total_loss': 0.9214171,\n",
      " 'learning_rate': 0.047999598}\n",
      "I0623 10:13:14.363627 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.51535994,\n",
      " 'Loss/localization_loss': 0.2529274,\n",
      " 'Loss/regularization_loss': 0.1531298,\n",
      " 'Loss/total_loss': 0.9214171,\n",
      " 'learning_rate': 0.047999598}\n",
      "INFO:tensorflow:Step 500 per-step time 5.301s\n",
      "I0623 10:22:04.475587 140561471125312 model_lib_v2.py:707] Step 500 per-step time 5.301s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.44251916,\n",
      " 'Loss/localization_loss': 0.29125056,\n",
      " 'Loss/regularization_loss': 0.1530984,\n",
      " 'Loss/total_loss': 0.8868681,\n",
      " 'learning_rate': 0.053333}\n",
      "I0623 10:22:04.475844 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.44251916,\n",
      " 'Loss/localization_loss': 0.29125056,\n",
      " 'Loss/regularization_loss': 0.1530984,\n",
      " 'Loss/total_loss': 0.8868681,\n",
      " 'learning_rate': 0.053333}\n",
      "INFO:tensorflow:Step 600 per-step time 5.336s\n",
      "I0623 10:30:58.094030 140561471125312 model_lib_v2.py:707] Step 600 per-step time 5.336s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.31190735,\n",
      " 'Loss/localization_loss': 0.1608458,\n",
      " 'Loss/regularization_loss': 0.15307114,\n",
      " 'Loss/total_loss': 0.62582433,\n",
      " 'learning_rate': 0.0586664}\n",
      "I0623 10:30:58.094328 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.31190735,\n",
      " 'Loss/localization_loss': 0.1608458,\n",
      " 'Loss/regularization_loss': 0.15307114,\n",
      " 'Loss/total_loss': 0.62582433,\n",
      " 'learning_rate': 0.0586664}\n",
      "INFO:tensorflow:Step 700 per-step time 5.447s\n",
      "I0623 10:40:02.807075 140561471125312 model_lib_v2.py:707] Step 700 per-step time 5.447s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.28660107,\n",
      " 'Loss/localization_loss': 0.12872735,\n",
      " 'Loss/regularization_loss': 0.15303575,\n",
      " 'Loss/total_loss': 0.56836414,\n",
      " 'learning_rate': 0.0639998}\n",
      "I0623 10:40:02.807348 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.28660107,\n",
      " 'Loss/localization_loss': 0.12872735,\n",
      " 'Loss/regularization_loss': 0.15303575,\n",
      " 'Loss/total_loss': 0.56836414,\n",
      " 'learning_rate': 0.0639998}\n",
      "INFO:tensorflow:Step 800 per-step time 5.683s\n",
      "I0623 10:49:31.076294 140561471125312 model_lib_v2.py:707] Step 800 per-step time 5.683s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27051416,\n",
      " 'Loss/localization_loss': 0.16103244,\n",
      " 'Loss/regularization_loss': 0.15298624,\n",
      " 'Loss/total_loss': 0.58453286,\n",
      " 'learning_rate': 0.069333196}\n",
      "I0623 10:49:31.076560 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.27051416,\n",
      " 'Loss/localization_loss': 0.16103244,\n",
      " 'Loss/regularization_loss': 0.15298624,\n",
      " 'Loss/total_loss': 0.58453286,\n",
      " 'learning_rate': 0.069333196}\n",
      "INFO:tensorflow:Step 900 per-step time 5.625s\n",
      "I0623 10:58:53.600631 140561471125312 model_lib_v2.py:707] Step 900 per-step time 5.625s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.25730804,\n",
      " 'Loss/localization_loss': 0.15729237,\n",
      " 'Loss/regularization_loss': 0.15291388,\n",
      " 'Loss/total_loss': 0.5675143,\n",
      " 'learning_rate': 0.074666604}\n",
      "I0623 10:58:53.600895 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.25730804,\n",
      " 'Loss/localization_loss': 0.15729237,\n",
      " 'Loss/regularization_loss': 0.15291388,\n",
      " 'Loss/total_loss': 0.5675143,\n",
      " 'learning_rate': 0.074666604}\n",
      "INFO:tensorflow:Step 1000 per-step time 5.676s\n",
      "I0623 11:08:21.197217 140561471125312 model_lib_v2.py:707] Step 1000 per-step time 5.676s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1978687,\n",
      " 'Loss/localization_loss': 0.10545645,\n",
      " 'Loss/regularization_loss': 0.15277997,\n",
      " 'Loss/total_loss': 0.4561051,\n",
      " 'learning_rate': 0.08}\n",
      "I0623 11:08:21.197491 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.1978687,\n",
      " 'Loss/localization_loss': 0.10545645,\n",
      " 'Loss/regularization_loss': 0.15277997,\n",
      " 'Loss/total_loss': 0.4561051,\n",
      " 'learning_rate': 0.08}\n",
      "INFO:tensorflow:Step 1100 per-step time 5.247s\n",
      "I0623 11:17:05.938818 140561471125312 model_lib_v2.py:707] Step 1100 per-step time 5.247s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1752229,\n",
      " 'Loss/localization_loss': 0.12771496,\n",
      " 'Loss/regularization_loss': 0.15247606,\n",
      " 'Loss/total_loss': 0.4554139,\n",
      " 'learning_rate': 0.07999918}\n",
      "I0623 11:17:05.939099 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.1752229,\n",
      " 'Loss/localization_loss': 0.12771496,\n",
      " 'Loss/regularization_loss': 0.15247606,\n",
      " 'Loss/total_loss': 0.4554139,\n",
      " 'learning_rate': 0.07999918}\n",
      "INFO:tensorflow:Step 1200 per-step time 5.555s\n",
      "I0623 11:26:21.446092 140561471125312 model_lib_v2.py:707] Step 1200 per-step time 5.555s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17190145,\n",
      " 'Loss/localization_loss': 0.0904117,\n",
      " 'Loss/regularization_loss': 0.15198606,\n",
      " 'Loss/total_loss': 0.4142992,\n",
      " 'learning_rate': 0.079996705}\n",
      "I0623 11:26:21.446373 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.17190145,\n",
      " 'Loss/localization_loss': 0.0904117,\n",
      " 'Loss/regularization_loss': 0.15198606,\n",
      " 'Loss/total_loss': 0.4142992,\n",
      " 'learning_rate': 0.079996705}\n",
      "INFO:tensorflow:Step 1300 per-step time 5.246s\n",
      "I0623 11:35:06.033237 140561471125312 model_lib_v2.py:707] Step 1300 per-step time 5.246s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17200847,\n",
      " 'Loss/localization_loss': 0.07239203,\n",
      " 'Loss/regularization_loss': 0.15148638,\n",
      " 'Loss/total_loss': 0.3958869,\n",
      " 'learning_rate': 0.0799926}\n",
      "I0623 11:35:06.033500 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.17200847,\n",
      " 'Loss/localization_loss': 0.07239203,\n",
      " 'Loss/regularization_loss': 0.15148638,\n",
      " 'Loss/total_loss': 0.3958869,\n",
      " 'learning_rate': 0.0799926}\n",
      "INFO:tensorflow:Step 1400 per-step time 5.135s\n",
      "I0623 11:43:39.532068 140561471125312 model_lib_v2.py:707] Step 1400 per-step time 5.135s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17016824,\n",
      " 'Loss/localization_loss': 0.11150652,\n",
      " 'Loss/regularization_loss': 0.15093249,\n",
      " 'Loss/total_loss': 0.43260723,\n",
      " 'learning_rate': 0.07998685}\n",
      "I0623 11:43:39.532345 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.17016824,\n",
      " 'Loss/localization_loss': 0.11150652,\n",
      " 'Loss/regularization_loss': 0.15093249,\n",
      " 'Loss/total_loss': 0.43260723,\n",
      " 'learning_rate': 0.07998685}\n",
      "INFO:tensorflow:Step 1500 per-step time 5.117s\n",
      "I0623 11:52:11.189750 140561471125312 model_lib_v2.py:707] Step 1500 per-step time 5.117s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14028573,\n",
      " 'Loss/localization_loss': 0.076647915,\n",
      " 'Loss/regularization_loss': 0.15039766,\n",
      " 'Loss/total_loss': 0.3673313,\n",
      " 'learning_rate': 0.07997945}\n",
      "I0623 11:52:11.190023 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.14028573,\n",
      " 'Loss/localization_loss': 0.076647915,\n",
      " 'Loss/regularization_loss': 0.15039766,\n",
      " 'Loss/total_loss': 0.3673313,\n",
      " 'learning_rate': 0.07997945}\n",
      "INFO:tensorflow:Step 1600 per-step time 5.086s\n",
      "I0623 12:00:39.837360 140561471125312 model_lib_v2.py:707] Step 1600 per-step time 5.086s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13221964,\n",
      " 'Loss/localization_loss': 0.060565796,\n",
      " 'Loss/regularization_loss': 0.14980717,\n",
      " 'Loss/total_loss': 0.34259263,\n",
      " 'learning_rate': 0.079970405}\n",
      "I0623 12:00:39.837689 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.13221964,\n",
      " 'Loss/localization_loss': 0.060565796,\n",
      " 'Loss/regularization_loss': 0.14980717,\n",
      " 'Loss/total_loss': 0.34259263,\n",
      " 'learning_rate': 0.079970405}\n",
      "INFO:tensorflow:Step 1700 per-step time 5.193s\n",
      "I0623 12:09:19.185052 140561471125312 model_lib_v2.py:707] Step 1700 per-step time 5.193s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1444921,\n",
      " 'Loss/localization_loss': 0.09403233,\n",
      " 'Loss/regularization_loss': 0.14921908,\n",
      " 'Loss/total_loss': 0.38774353,\n",
      " 'learning_rate': 0.07995972}\n",
      "I0623 12:09:19.185313 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.1444921,\n",
      " 'Loss/localization_loss': 0.09403233,\n",
      " 'Loss/regularization_loss': 0.14921908,\n",
      " 'Loss/total_loss': 0.38774353,\n",
      " 'learning_rate': 0.07995972}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 1800 per-step time 5.188s\n",
      "I0623 12:17:57.983545 140561471125312 model_lib_v2.py:707] Step 1800 per-step time 5.188s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13503303,\n",
      " 'Loss/localization_loss': 0.060196254,\n",
      " 'Loss/regularization_loss': 0.14863648,\n",
      " 'Loss/total_loss': 0.34386575,\n",
      " 'learning_rate': 0.0799474}\n",
      "I0623 12:17:57.983904 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.13503303,\n",
      " 'Loss/localization_loss': 0.060196254,\n",
      " 'Loss/regularization_loss': 0.14863648,\n",
      " 'Loss/total_loss': 0.34386575,\n",
      " 'learning_rate': 0.0799474}\n",
      "INFO:tensorflow:Step 1900 per-step time 5.371s\n",
      "I0623 12:26:55.117759 140561471125312 model_lib_v2.py:707] Step 1900 per-step time 5.371s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13923706,\n",
      " 'Loss/localization_loss': 0.07751569,\n",
      " 'Loss/regularization_loss': 0.1480144,\n",
      " 'Loss/total_loss': 0.36476713,\n",
      " 'learning_rate': 0.07993342}\n",
      "I0623 12:26:55.118026 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.13923706,\n",
      " 'Loss/localization_loss': 0.07751569,\n",
      " 'Loss/regularization_loss': 0.1480144,\n",
      " 'Loss/total_loss': 0.36476713,\n",
      " 'learning_rate': 0.07993342}\n",
      "INFO:tensorflow:Step 2000 per-step time 5.168s\n",
      "I0623 12:35:31.884542 140561471125312 model_lib_v2.py:707] Step 2000 per-step time 5.168s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13591447,\n",
      " 'Loss/localization_loss': 0.08524618,\n",
      " 'Loss/regularization_loss': 0.14739186,\n",
      " 'Loss/total_loss': 0.3685525,\n",
      " 'learning_rate': 0.07991781}\n",
      "I0623 12:35:31.884809 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.13591447,\n",
      " 'Loss/localization_loss': 0.08524618,\n",
      " 'Loss/regularization_loss': 0.14739186,\n",
      " 'Loss/total_loss': 0.3685525,\n",
      " 'learning_rate': 0.07991781}\n",
      "INFO:tensorflow:Step 2100 per-step time 5.124s\n",
      "I0623 12:44:04.241615 140561471125312 model_lib_v2.py:707] Step 2100 per-step time 5.124s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.120862596,\n",
      " 'Loss/localization_loss': 0.055045266,\n",
      " 'Loss/regularization_loss': 0.14677672,\n",
      " 'Loss/total_loss': 0.3226846,\n",
      " 'learning_rate': 0.07990056}\n",
      "I0623 12:44:04.241887 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.120862596,\n",
      " 'Loss/localization_loss': 0.055045266,\n",
      " 'Loss/regularization_loss': 0.14677672,\n",
      " 'Loss/total_loss': 0.3226846,\n",
      " 'learning_rate': 0.07990056}\n",
      "INFO:tensorflow:Step 2200 per-step time 5.085s\n",
      "I0623 12:52:32.709922 140561471125312 model_lib_v2.py:707] Step 2200 per-step time 5.085s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.115473524,\n",
      " 'Loss/localization_loss': 0.05882168,\n",
      " 'Loss/regularization_loss': 0.14610365,\n",
      " 'Loss/total_loss': 0.32039887,\n",
      " 'learning_rate': 0.07988167}\n",
      "I0623 12:52:32.710203 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.115473524,\n",
      " 'Loss/localization_loss': 0.05882168,\n",
      " 'Loss/regularization_loss': 0.14610365,\n",
      " 'Loss/total_loss': 0.32039887,\n",
      " 'learning_rate': 0.07988167}\n",
      "INFO:tensorflow:Step 2300 per-step time 5.041s\n",
      "I0623 13:00:56.780161 140561471125312 model_lib_v2.py:707] Step 2300 per-step time 5.041s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13119876,\n",
      " 'Loss/localization_loss': 0.07133954,\n",
      " 'Loss/regularization_loss': 0.14545043,\n",
      " 'Loss/total_loss': 0.34798872,\n",
      " 'learning_rate': 0.07986114}\n",
      "I0623 13:00:56.780441 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.13119876,\n",
      " 'Loss/localization_loss': 0.07133954,\n",
      " 'Loss/regularization_loss': 0.14545043,\n",
      " 'Loss/total_loss': 0.34798872,\n",
      " 'learning_rate': 0.07986114}\n",
      "INFO:tensorflow:Step 2400 per-step time 5.006s\n",
      "I0623 13:09:17.383802 140561471125312 model_lib_v2.py:707] Step 2400 per-step time 5.006s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13707422,\n",
      " 'Loss/localization_loss': 0.074469976,\n",
      " 'Loss/regularization_loss': 0.1447903,\n",
      " 'Loss/total_loss': 0.3563345,\n",
      " 'learning_rate': 0.07983897}\n",
      "I0623 13:09:17.384072 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.13707422,\n",
      " 'Loss/localization_loss': 0.074469976,\n",
      " 'Loss/regularization_loss': 0.1447903,\n",
      " 'Loss/total_loss': 0.3563345,\n",
      " 'learning_rate': 0.07983897}\n",
      "INFO:tensorflow:Step 2500 per-step time 5.171s\n",
      "I0623 13:17:54.434570 140561471125312 model_lib_v2.py:707] Step 2500 per-step time 5.171s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.107744575,\n",
      " 'Loss/localization_loss': 0.04213478,\n",
      " 'Loss/regularization_loss': 0.14416084,\n",
      " 'Loss/total_loss': 0.2940402,\n",
      " 'learning_rate': 0.079815164}\n",
      "I0623 13:17:54.434854 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.107744575,\n",
      " 'Loss/localization_loss': 0.04213478,\n",
      " 'Loss/regularization_loss': 0.14416084,\n",
      " 'Loss/total_loss': 0.2940402,\n",
      " 'learning_rate': 0.079815164}\n",
      "INFO:tensorflow:Step 2600 per-step time 5.294s\n",
      "I0623 13:26:43.798550 140561471125312 model_lib_v2.py:707] Step 2600 per-step time 5.294s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1009081,\n",
      " 'Loss/localization_loss': 0.064439364,\n",
      " 'Loss/regularization_loss': 0.14349028,\n",
      " 'Loss/total_loss': 0.30883774,\n",
      " 'learning_rate': 0.07978972}\n",
      "I0623 13:26:43.798812 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.1009081,\n",
      " 'Loss/localization_loss': 0.064439364,\n",
      " 'Loss/regularization_loss': 0.14349028,\n",
      " 'Loss/total_loss': 0.30883774,\n",
      " 'learning_rate': 0.07978972}\n",
      "INFO:tensorflow:Step 2700 per-step time 5.130s\n",
      "I0623 13:35:16.780209 140561471125312 model_lib_v2.py:707] Step 2700 per-step time 5.130s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11338299,\n",
      " 'Loss/localization_loss': 0.05690038,\n",
      " 'Loss/regularization_loss': 0.14281932,\n",
      " 'Loss/total_loss': 0.3131027,\n",
      " 'learning_rate': 0.07976264}\n",
      "I0623 13:35:16.780548 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.11338299,\n",
      " 'Loss/localization_loss': 0.05690038,\n",
      " 'Loss/regularization_loss': 0.14281932,\n",
      " 'Loss/total_loss': 0.3131027,\n",
      " 'learning_rate': 0.07976264}\n",
      "INFO:tensorflow:Step 2800 per-step time 5.103s\n",
      "I0623 13:43:47.045047 140561471125312 model_lib_v2.py:707] Step 2800 per-step time 5.103s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10018567,\n",
      " 'Loss/localization_loss': 0.04285422,\n",
      " 'Loss/regularization_loss': 0.1421662,\n",
      " 'Loss/total_loss': 0.28520608,\n",
      " 'learning_rate': 0.07973392}\n",
      "I0623 13:43:47.045373 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.10018567,\n",
      " 'Loss/localization_loss': 0.04285422,\n",
      " 'Loss/regularization_loss': 0.1421662,\n",
      " 'Loss/total_loss': 0.28520608,\n",
      " 'learning_rate': 0.07973392}\n",
      "INFO:tensorflow:Step 2900 per-step time 5.040s\n",
      "I0623 13:52:11.034114 140561471125312 model_lib_v2.py:707] Step 2900 per-step time 5.040s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1075259,\n",
      " 'Loss/localization_loss': 0.06364928,\n",
      " 'Loss/regularization_loss': 0.14155921,\n",
      " 'Loss/total_loss': 0.3127344,\n",
      " 'learning_rate': 0.07970358}\n",
      "I0623 13:52:11.034381 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.1075259,\n",
      " 'Loss/localization_loss': 0.06364928,\n",
      " 'Loss/regularization_loss': 0.14155921,\n",
      " 'Loss/total_loss': 0.3127344,\n",
      " 'learning_rate': 0.07970358}\n",
      "INFO:tensorflow:Step 3000 per-step time 5.026s\n",
      "I0623 14:00:33.602804 140561471125312 model_lib_v2.py:707] Step 3000 per-step time 5.026s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10083698,\n",
      " 'Loss/localization_loss': 0.03743594,\n",
      " 'Loss/regularization_loss': 0.14089507,\n",
      " 'Loss/total_loss': 0.27916798,\n",
      " 'learning_rate': 0.0796716}\n",
      "I0623 14:00:33.603076 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.10083698,\n",
      " 'Loss/localization_loss': 0.03743594,\n",
      " 'Loss/regularization_loss': 0.14089507,\n",
      " 'Loss/total_loss': 0.27916798,\n",
      " 'learning_rate': 0.0796716}\n",
      "INFO:tensorflow:Step 3100 per-step time 5.149s\n",
      "I0623 14:09:08.515926 140561471125312 model_lib_v2.py:707] Step 3100 per-step time 5.149s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08814669,\n",
      " 'Loss/localization_loss': 0.044690706,\n",
      " 'Loss/regularization_loss': 0.14023924,\n",
      " 'Loss/total_loss': 0.27307662,\n",
      " 'learning_rate': 0.07963799}\n",
      "I0623 14:09:08.516215 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.08814669,\n",
      " 'Loss/localization_loss': 0.044690706,\n",
      " 'Loss/regularization_loss': 0.14023924,\n",
      " 'Loss/total_loss': 0.27307662,\n",
      " 'learning_rate': 0.07963799}\n",
      "INFO:tensorflow:Step 3200 per-step time 5.246s\n",
      "I0623 14:17:53.164202 140561471125312 model_lib_v2.py:707] Step 3200 per-step time 5.246s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.103601895,\n",
      " 'Loss/localization_loss': 0.06325273,\n",
      " 'Loss/regularization_loss': 0.13956669,\n",
      " 'Loss/total_loss': 0.3064213,\n",
      " 'learning_rate': 0.07960275}\n",
      "I0623 14:17:53.164468 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.103601895,\n",
      " 'Loss/localization_loss': 0.06325273,\n",
      " 'Loss/regularization_loss': 0.13956669,\n",
      " 'Loss/total_loss': 0.3064213,\n",
      " 'learning_rate': 0.07960275}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 3300 per-step time 5.442s\n",
      "I0623 14:26:57.401328 140561471125312 model_lib_v2.py:707] Step 3300 per-step time 5.442s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10590132,\n",
      " 'Loss/localization_loss': 0.048713904,\n",
      " 'Loss/regularization_loss': 0.13891402,\n",
      " 'Loss/total_loss': 0.29352924,\n",
      " 'learning_rate': 0.07956588}\n",
      "I0623 14:26:57.401593 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.10590132,\n",
      " 'Loss/localization_loss': 0.048713904,\n",
      " 'Loss/regularization_loss': 0.13891402,\n",
      " 'Loss/total_loss': 0.29352924,\n",
      " 'learning_rate': 0.07956588}\n",
      "INFO:tensorflow:Step 3400 per-step time 5.453s\n",
      "I0623 14:36:02.724116 140561471125312 model_lib_v2.py:707] Step 3400 per-step time 5.453s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11729822,\n",
      " 'Loss/localization_loss': 0.043495692,\n",
      " 'Loss/regularization_loss': 0.13824984,\n",
      " 'Loss/total_loss': 0.29904374,\n",
      " 'learning_rate': 0.079527386}\n",
      "I0623 14:36:02.724492 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.11729822,\n",
      " 'Loss/localization_loss': 0.043495692,\n",
      " 'Loss/regularization_loss': 0.13824984,\n",
      " 'Loss/total_loss': 0.29904374,\n",
      " 'learning_rate': 0.079527386}\n",
      "INFO:tensorflow:Step 3500 per-step time 5.368s\n",
      "I0623 14:44:59.564005 140561471125312 model_lib_v2.py:707] Step 3500 per-step time 5.368s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10299987,\n",
      " 'Loss/localization_loss': 0.051510073,\n",
      " 'Loss/regularization_loss': 0.13759187,\n",
      " 'Loss/total_loss': 0.2921018,\n",
      " 'learning_rate': 0.07948727}\n",
      "I0623 14:44:59.564325 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.10299987,\n",
      " 'Loss/localization_loss': 0.051510073,\n",
      " 'Loss/regularization_loss': 0.13759187,\n",
      " 'Loss/total_loss': 0.2921018,\n",
      " 'learning_rate': 0.07948727}\n",
      "INFO:tensorflow:Step 3600 per-step time 5.364s\n",
      "I0623 14:53:55.954532 140561471125312 model_lib_v2.py:707] Step 3600 per-step time 5.364s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09479435,\n",
      " 'Loss/localization_loss': 0.044536218,\n",
      " 'Loss/regularization_loss': 0.13693556,\n",
      " 'Loss/total_loss': 0.27626613,\n",
      " 'learning_rate': 0.079445526}\n",
      "I0623 14:53:55.954798 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.09479435,\n",
      " 'Loss/localization_loss': 0.044536218,\n",
      " 'Loss/regularization_loss': 0.13693556,\n",
      " 'Loss/total_loss': 0.27626613,\n",
      " 'learning_rate': 0.079445526}\n",
      "INFO:tensorflow:Step 3700 per-step time 5.810s\n",
      "I0623 15:03:36.973546 140561471125312 model_lib_v2.py:707] Step 3700 per-step time 5.810s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08295378,\n",
      " 'Loss/localization_loss': 0.05103328,\n",
      " 'Loss/regularization_loss': 0.13629289,\n",
      " 'Loss/total_loss': 0.27027994,\n",
      " 'learning_rate': 0.07940216}\n",
      "I0623 15:03:36.973845 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.08295378,\n",
      " 'Loss/localization_loss': 0.05103328,\n",
      " 'Loss/regularization_loss': 0.13629289,\n",
      " 'Loss/total_loss': 0.27027994,\n",
      " 'learning_rate': 0.07940216}\n",
      "INFO:tensorflow:Step 3800 per-step time 6.174s\n",
      "I0623 15:13:54.397737 140561471125312 model_lib_v2.py:707] Step 3800 per-step time 6.174s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10097803,\n",
      " 'Loss/localization_loss': 0.04279022,\n",
      " 'Loss/regularization_loss': 0.1356531,\n",
      " 'Loss/total_loss': 0.27942133,\n",
      " 'learning_rate': 0.079357184}\n",
      "I0623 15:13:54.398035 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.10097803,\n",
      " 'Loss/localization_loss': 0.04279022,\n",
      " 'Loss/regularization_loss': 0.1356531,\n",
      " 'Loss/total_loss': 0.27942133,\n",
      " 'learning_rate': 0.079357184}\n",
      "INFO:tensorflow:Step 3900 per-step time 5.514s\n",
      "I0623 15:23:05.842234 140561471125312 model_lib_v2.py:707] Step 3900 per-step time 5.514s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.093306765,\n",
      " 'Loss/localization_loss': 0.052003004,\n",
      " 'Loss/regularization_loss': 0.13501087,\n",
      " 'Loss/total_loss': 0.28032064,\n",
      " 'learning_rate': 0.07931058}\n",
      "I0623 15:23:05.842514 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.093306765,\n",
      " 'Loss/localization_loss': 0.052003004,\n",
      " 'Loss/regularization_loss': 0.13501087,\n",
      " 'Loss/total_loss': 0.28032064,\n",
      " 'learning_rate': 0.07931058}\n",
      "INFO:tensorflow:Step 4000 per-step time 5.610s\n",
      "I0623 15:32:26.812579 140561471125312 model_lib_v2.py:707] Step 4000 per-step time 5.610s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.101592235,\n",
      " 'Loss/localization_loss': 0.040262107,\n",
      " 'Loss/regularization_loss': 0.13436556,\n",
      " 'Loss/total_loss': 0.2762199,\n",
      " 'learning_rate': 0.07926236}\n",
      "I0623 15:32:26.812856 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.101592235,\n",
      " 'Loss/localization_loss': 0.040262107,\n",
      " 'Loss/regularization_loss': 0.13436556,\n",
      " 'Loss/total_loss': 0.2762199,\n",
      " 'learning_rate': 0.07926236}\n",
      "INFO:tensorflow:Step 4100 per-step time 5.487s\n",
      "I0623 15:41:35.485682 140561471125312 model_lib_v2.py:707] Step 4100 per-step time 5.487s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.091865264,\n",
      " 'Loss/localization_loss': 0.056647845,\n",
      " 'Loss/regularization_loss': 0.13370806,\n",
      " 'Loss/total_loss': 0.28222117,\n",
      " 'learning_rate': 0.07921253}\n",
      "I0623 15:41:35.486002 140561471125312 model_lib_v2.py:708] {'Loss/classification_loss': 0.091865264,\n",
      " 'Loss/localization_loss': 0.056647845,\n",
      " 'Loss/regularization_loss': 0.13370806,\n",
      " 'Loss/total_loss': 0.28222117,\n",
      " 'learning_rate': 0.07921253}\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py --model_dir=../models/ssd_mobilenet_v2__taco --pipeline_config_path=../models/ssd_mobilenet_v2__taco/pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90555574",
   "metadata": {},
   "source": [
    "### 3. Exporting the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0836335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /home/tensorflow/models/research/object_detection/exporter_main_v2.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a9aee82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tensorflow/waste/work'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55840140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0624 12:20:05.140064 139780628993856 deprecation.py:616] From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f20ac779320>, because it is not built.\n",
      "W0624 12:20:26.325408 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f20ac779320>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f20ac723a90>, because it is not built.\n",
      "W0624 12:20:26.456480 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f20ac723a90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b506f98>, because it is not built.\n",
      "W0624 12:20:26.456670 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b506f98>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b506240>, because it is not built.\n",
      "W0624 12:20:26.456739 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b506240>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f208b5062e8>, because it is not built.\n",
      "W0624 12:20:26.456793 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f208b5062e8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b53e860>, because it is not built.\n",
      "W0624 12:20:26.456836 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b53e860>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b53eb38>, because it is not built.\n",
      "W0624 12:20:26.456878 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b53eb38>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f208b53eb00>, because it is not built.\n",
      "W0624 12:20:26.456922 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f208b53eb00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b7081d0>, because it is not built.\n",
      "W0624 12:20:26.456964 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b7081d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b708b38>, because it is not built.\n",
      "W0624 12:20:26.457009 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b708b38>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f208b7088d0>, because it is not built.\n",
      "W0624 12:20:26.457050 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f208b7088d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b51c7f0>, because it is not built.\n",
      "W0624 12:20:26.457090 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b51c7f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b51c1d0>, because it is not built.\n",
      "W0624 12:20:26.457130 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b51c1d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f20ac723dd8>, because it is not built.\n",
      "W0624 12:20:26.457173 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f20ac723dd8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b567e80>, because it is not built.\n",
      "W0624 12:20:26.457215 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b567e80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b567cf8>, because it is not built.\n",
      "W0624 12:20:26.457257 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b567cf8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4e90b8>, because it is not built.\n",
      "W0624 12:20:26.457298 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4e90b8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4e9128>, because it is not built.\n",
      "W0624 12:20:26.457338 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4e9128>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4e9c18>, because it is not built.\n",
      "W0624 12:20:26.457418 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4e9c18>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4e9dd8>, because it is not built.\n",
      "W0624 12:20:26.457463 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4e9dd8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b523278>, because it is not built.\n",
      "W0624 12:20:26.457504 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b523278>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f20ac723e10>, because it is not built.\n",
      "W0624 12:20:26.457545 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f20ac723e10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4c65c0>, because it is not built.\n",
      "W0624 12:20:26.457586 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4c65c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4c6668>, because it is not built.\n",
      "W0624 12:20:26.457627 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4c6668>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4c6898>, because it is not built.\n",
      "W0624 12:20:26.457668 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4c6898>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4c6b70>, because it is not built.\n",
      "W0624 12:20:26.457709 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4c6b70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4c6e10>, because it is not built.\n",
      "W0624 12:20:26.457750 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4c6e10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4c6e80>, because it is not built.\n",
      "W0624 12:20:26.457792 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4c6e80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4cc390>, because it is not built.\n",
      "W0624 12:20:26.457833 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4cc390>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f20ac4fc0b8>, because it is not built.\n",
      "W0624 12:20:26.457874 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f20ac4fc0b8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4e21d0>, because it is not built.\n",
      "W0624 12:20:26.457916 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4e21d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4e2320>, because it is not built.\n",
      "W0624 12:20:26.457957 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4e2320>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4e2630>, because it is not built.\n",
      "W0624 12:20:26.457997 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4e2630>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4e2588>, because it is not built.\n",
      "W0624 12:20:26.458037 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4e2588>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4e2a20>, because it is not built.\n",
      "W0624 12:20:26.458077 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b4e2a20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4e2a90>, because it is not built.\n",
      "W0624 12:20:26.458117 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b4e2a90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f20ac5283c8>, because it is not built.\n",
      "W0624 12:20:26.458159 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f20ac5283c8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f20ac723e48>, because it is not built.\n",
      "W0624 12:20:26.458200 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f20ac723e48>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b516748>, because it is not built.\n",
      "W0624 12:20:26.458241 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b516748>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b516400>, because it is not built.\n",
      "W0624 12:20:26.458282 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b516400>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b516240>, because it is not built.\n",
      "W0624 12:20:26.458322 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b516240>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b5164e0>, because it is not built.\n",
      "W0624 12:20:26.458363 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b5164e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b516668>, because it is not built.\n",
      "W0624 12:20:26.458404 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b516668>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b5164a8>, because it is not built.\n",
      "W0624 12:20:26.458447 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f208b5164a8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b516fd0>, because it is not built.\n",
      "W0624 12:20:26.458491 139780628993856 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7f208b516fd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0624 12:20:45.293895 139780628993856 save.py:254] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: ../models/trained/saved_model/assets\n",
      "I0624 12:20:48.767588 139780628993856 builder_impl.py:781] Assets written to: ../models/trained/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to ../models/trained/pipeline.config\n",
      "I0624 12:20:49.403180 139780628993856 config_util.py:254] Writing pipeline config file to ../models/trained/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ../models/ssd_mobilenet_v2__taco/pipeline.config --trained_checkpoint_dir ../models/ssd_mobilenet_v2__taco/ --output_directory ../models/trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a0b84",
   "metadata": {},
   "source": [
    "Export for TFLite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9796aa8",
   "metadata": {},
   "source": [
    "!pip install tflite_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d7a97e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fc1e8368d30>, because it is not built.\n",
      "W0627 09:20:29.119112 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fc1e8368d30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fc1e8238208>, because it is not built.\n",
      "W0627 09:20:29.262025 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fc1e8238208>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e01c8240>, because it is not built.\n",
      "W0627 09:20:29.262196 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e01c8240>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e01c8d68>, because it is not built.\n",
      "W0627 09:20:29.262248 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e01c8d68>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fc1e01c8860>, because it is not built.\n",
      "W0627 09:20:29.262292 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fc1e01c8860>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e01c8c50>, because it is not built.\n",
      "W0627 09:20:29.262336 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e01c8c50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e034d4e0>, because it is not built.\n",
      "W0627 09:20:29.262379 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e034d4e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fc1e034d208>, because it is not built.\n",
      "W0627 09:20:29.262420 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fc1e034d208>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e034d8d0>, because it is not built.\n",
      "W0627 09:20:29.262461 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e034d8d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e034dd68>, because it is not built.\n",
      "W0627 09:20:29.262502 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e034dd68>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fc1e034d0b8>, because it is not built.\n",
      "W0627 09:20:29.262543 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fc1e034d0b8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e034ecc0>, because it is not built.\n",
      "W0627 09:20:29.262583 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e034ecc0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e034e080>, because it is not built.\n",
      "W0627 09:20:29.262625 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e034e080>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e82388d0>, because it is not built.\n",
      "W0627 09:20:29.262666 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e82388d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e02cb940>, because it is not built.\n",
      "W0627 09:20:29.262706 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e02cb940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e036a2e8>, because it is not built.\n",
      "W0627 09:20:29.262746 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e036a2e8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e036a978>, because it is not built.\n",
      "W0627 09:20:29.262786 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e036a978>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e036aa20>, because it is not built.\n",
      "W0627 09:20:29.262827 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e036aa20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e036aef0>, because it is not built.\n",
      "W0627 09:20:29.262871 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e036aef0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e036acc0>, because it is not built.\n",
      "W0627 09:20:29.262915 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e036acc0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e036abe0>, because it is not built.\n",
      "W0627 09:20:29.262957 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e036abe0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e8238908>, because it is not built.\n",
      "W0627 09:20:29.262999 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e8238908>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e0187908>, because it is not built.\n",
      "W0627 09:20:29.263043 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e0187908>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e01877f0>, because it is not built.\n",
      "W0627 09:20:29.263085 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e01877f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e01870b8>, because it is not built.\n",
      "W0627 09:20:29.263130 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e01870b8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e0187e80>, because it is not built.\n",
      "W0627 09:20:29.263172 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e0187e80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e0187ac8>, because it is not built.\n",
      "W0627 09:20:29.263214 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e0187ac8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e02e3198>, because it is not built.\n",
      "W0627 09:20:29.263256 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e02e3198>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e02e3208>, because it is not built.\n",
      "W0627 09:20:29.263298 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e02e3208>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e0243e48>, because it is not built.\n",
      "W0627 09:20:29.263340 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e0243e48>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e0183a20>, because it is not built.\n",
      "W0627 09:20:29.263383 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e0183a20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e0183b38>, because it is not built.\n",
      "W0627 09:20:29.263427 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e0183b38>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e0183dd8>, because it is not built.\n",
      "W0627 09:20:29.263472 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e0183dd8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e0183f98>, because it is not built.\n",
      "W0627 09:20:29.263515 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e0183f98>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e01e34e0>, because it is not built.\n",
      "W0627 09:20:29.263562 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e01e34e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e01e3160>, because it is not built.\n",
      "W0627 09:20:29.263606 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e01e3160>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e01e3048>, because it is not built.\n",
      "W0627 09:20:29.263654 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e01e3048>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e8238940>, because it is not built.\n",
      "W0627 09:20:29.263697 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e8238940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e024d6d8>, because it is not built.\n",
      "W0627 09:20:29.263740 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e024d6d8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e024d908>, because it is not built.\n",
      "W0627 09:20:29.263782 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e024d908>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e024dd30>, because it is not built.\n",
      "W0627 09:20:29.263825 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e024dd30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e024d4e0>, because it is not built.\n",
      "W0627 09:20:29.263868 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e024d4e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e024de10>, because it is not built.\n",
      "W0627 09:20:29.263911 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e024de10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e024d208>, because it is not built.\n",
      "W0627 09:20:29.263955 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fc1e024d208>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e02493c8>, because it is not built.\n",
      "W0627 09:20:29.263999 140472835090240 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fc1e02493c8>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0627 09:20:43.172046 140472835090240 save.py:254] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: ../models/tflite/saved_model/assets\n",
      "I0627 09:20:46.072693 140472835090240 builder_impl.py:781] Assets written to: ../models/tflite/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "!python /home/tensorflow/models/research/object_detection/export_tflite_graph_tf2.py --trained_checkpoint_dir '../models/ssd_mobilenet_v2__taco/' --output_directory '../models/tflite/' --pipeline_config_path '../models/ssd_mobilenet_v2__taco/pipeline.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "188a00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('../models/tflite/saved_model/')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('../models/tflite/ssd_taco.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
