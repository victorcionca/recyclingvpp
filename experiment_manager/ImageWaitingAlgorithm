Object Properties:
    -   Extracted_Object_Tuple => (width: int, height: int, x1: int, y1: int, x2: int, y2: int, deadline: uint64)
        - A tuple that contains the width and height of the extracted region and it's coordinates from the original image.
        The deadline is determined by the time remaining for the object to reach the sorting bucket.

Input:
    - Extracted_Objects => [Extracted_Object_Tuple]
        -   A list of extracted regions.

    - DNN_List => [(width: int, height: int, estimated_proc_time: uint64)]
        -   A list containing the configuration details of each DNN model available.

    - Conveyor_Velocity => float
        -   The number of metres per millisecond the conveyor belt moves at.

    - Processor_image_post_filter => cv image_object
        - The image captured by the processor after filters have been applied to it.
    
    - Processor_original_boundaries => (width: int, height: int)
        - The width and height of the processor image pre-filtering.

    - Oracle_image => cv image_object
        - The filtered region of the oracles frame that is expected to enter 
        into the processor scope in the next frame.

Output:
    - offload => boolean
        - Indicates whether to mark extract objects for processing.
        - True => Offload the extracted regions for processing
        - False => Wait till the next frame

Steps:
    1.) Iterate through extracted region tuples, map each extracted region to a DNN model.
        For extremely large regions the processing time is the sum of the proc time for each fixed partition.

        Store the shortest remaining time.
        Store the coordinates details of the furthest object.

    2.) If (shortest_remaining_time - displacement_time <= 0)
            return true
    
    3.) If (furthest_x2 + conveyor_velocity > Processor_original_boundaries.width)
            return true
    
    4.) Based on the conveyor velocity, extract the region of the oracle image expected 
    to enter the processors scope in the next frame.

    5.) Determine the percentage of the filtered oracle region that is empty space
    6.) Determine the percentage of the processor image that is empty space.
    7.) Add together the the percentage of empty regions in the processor and the extracted oracle.

    8.) If the percentage of empty regions is expected to reduce in the next frame => return false else True

    